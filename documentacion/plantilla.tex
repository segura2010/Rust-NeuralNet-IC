%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Programming/Coding Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing assignment content.
%
% This template uses a Perl script as an example snippet of code, most other
% languages are also usable. Configure them in the "CODE INCLUSION 
% CONFIGURATION" section.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{hyperref} % Hyperlink
\usepackage{enumitem}

\usepackage[utf8]{inputenc} % Para tildes!

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorName} % Top left header
\rhead{\hmwkTitle - \hmwkTituloTarea} % Top center head
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Página\ \thepage\ de\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs


%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------


%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Inteligencia Computacional} % Assignment title
\newcommand{\hmwkSubtitulo}{Master en Ingeniería Informática} % Due date
\newcommand{\hmwkDueDate}{Miércoles 9 de Diciembre de 2015} % Due date
\newcommand{\hmwkTituloTarea}{Práctica 1: Redes Neuronales} % Class/lecture time
\newcommand{\hmwkAuthorName}{Luis Alberto Segura Delgado} % Your name

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\vspace{2in}
\textmd{\textbf{\hmwkTitle}}\\
\textmd{\textbf{\hmwkSubtitulo}}\\
\normalsize\textbf{\\\hmwkTituloTarea}\\
\vspace{0.1in}
\vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}
\date{\hmwkDueDate} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}
\inputencoding{latin1}
\maketitle


%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

% To have just one problem per page, simply put a \clearpage after each problem

\newpage
\tableofcontents

\newpage

\section{Introducción}
En esta práctica el objetivo es familiarizarse con técnicas de aprendizaje basadas en Redes Neuronales para resolver un problema concreto, en este caso, el reconocimiento de patrones numericos.
\\
En clase se han visto las redes neuronales más básicas, las originales. Y a partir de estás se ha ido profundizando hasta conocer el funcionamiento y las mejoras que se han ido añadiendo para que sean capaces de resolver mejor y de forma más eficiente los problemas, resolviendo los problemas iniciales que se descubrieron en los modelos más básicos. De esta forma, ahora conocemos una técnica de aprendizaje automático más que podemos usar para aquellos problemas que se nos planteen en el futuro, siempre que aplicar redes neuronales sea una estrategia correcta para resolver el problema.

\section{Implementación}
El trabajo de implementación realizado ha sido principalmente desarrollar por mi mismo una red neuronal multicapa y entrenarla ajustando los diferentes parámetros (tasa de aprendizaje, neuronas de cada capa, capas ocultas..) de forma que se obtuviese la menor tasa de error en la clasificación de los ejemplos del problema propuesto.

\subsection{Red Neuronal Multicapa Simple}
En primer lugar se ha implementado una red neuronal multicapa sencilla. La implementación se ha realizado en un nuevo lenguaje de programación similar a C/C++ llamado $Rust$\footnote{\url{https://www.rust-lang.org}}. La implementación en detalle se puede ver en el código que se entrega junto a esta documentación.
\\\\
La implementación es sencilla, y nos permite crear una red neuronal con el número de capas ocultas que deseemos. Simplemente tenemos que indicar el número de entradas (neuronas de entrada), el número de capas ocultas, el número de neuronas ocultas (todas las capas tendrán el mismo número de neuronas), el número de salidas de la red y la tasa de aprendizaje de la red a la hora de entrenar con BackPropagation. Automáticamente se creará una red neuronal con la topología indicada. La inicialización de los pesos es aleatoria, con valores entre -0.5 y 0.5, y el término $bias$ se inicializa para todas las neuronas a 1.0.
\\\\
Una vez que tenemos nuestra red neuronal creada, ésta debe poder ser ejecutada, para ellos se implementa una función $ejecutar$ que simplemente realiza las operaciones de multiplicar pesos por entradas y acumularlos, y finalmente calcular la salida final de las neuronas (y) en base a la función de activación, que en este caso es la función $Sigmoide$.

% https://en.wikibooks.org/wiki/LaTeX/Mathematics
\begin{equation}
	o = \sum _{ i=0 }^{ n }{ w_{ i }x_{ i } } +b_{ i }
\end{equation}
\begin{equation}
	y = \frac { 1 }{ 1+{ e }^{ -o } } 
\end{equation}

Para cada neurona se calcula su salida aplicandole la función $Sigmoide$, haciendo propagación hacia delante, finalmente obtenemos la salida de la red para unas entrada determinadas.
\\\\
Y ya solamente quedaba implementar un método para entrenar nuestra red neuronal. Este método es BackPropagation. Después de pelear mucho con las fórmulas y su implementación, finalmente parece que está implementado correctamente y funciona. El método de entrenamiento concreto es un entrenamiento $online$, es decir, los pesos de las neuronas se actualizan cada vez que le pasamos una entrada (foto de dígito) en función del error cometido al clasificar. Como sabemos, cada vez que se le pasa una entrada, se ejecuta la red, de forma que obtenemos la salida de la red. Se calcula el error de la clasificación y se propaga hacia atrás a todas las neuronas de la red para actualizar sus pesos en la medida en la que afectan a la salida (al error que se produce).
\\\\
Una vez que tenemos esta red neuronal sencilla y su método de entrenamiento, solo queda ponerla a entrenar para empezar a obtener los primeros resultados. Tras una serie de experimentos y pruebas con diferentes configuraciones (tasa de aprendizaje, número de neuronas ocultas, etc), vimos que los errores no se reducían suficiente, solían quedar en torno al 20\%, por lo que se han implementado algunas mejoras que se nos han ocurrido para tratar de reducir el error (de entrenamiento).

\subsection{Mejora en BackPropagation: \textit{BackPropagation con Refuerzo}}
En primer lugar se nos ocurrió que, como nuestra red neuronal se quedaba atascada en un porcentaje de error en torno al 20\% para el conjunto de entrenamiento, quizás podríamos "forzar" la red a aprender aquellos ejemplos que parecía que le costaban más. Para ello, se implementó una modificación de BackPropagation (\textit{BackPropagation con Refuerzo}) que, en primer lugar, entrenaba una época\footnote{pasada de todos los datos de entrenamiento una vez (los dígitos 60000)}. Después de entrenar en una época solamente, se calcula la tasa de error y se guardan los ejemplos en los que se ha equivocado. Y a continuación, se entrena una época usando solamente los ejemplos en los que ha fallado. Para este nuevo entrenamiento que solamente usa los ejemplo erróneos, la tasa de error se reduce para evitar que se "olviden" los ejemplos que ya se aprendieron. El entrenamiento con los ejemplos erróneos se realiza tantas veces como se indique. De forma que, una vez que se entrena la primera vez con salidas falladas, se vuelve a calcular el error y se guardan los nuevos errores, para entrenar con los nuevos errores solamente, y en cada iteración (época de refuerzo) se reduce progresivamente la tasa de error (esto de reducir la tasa de error parece funcionar bastante bien).
\\\\
Con este método de entrenamiento, nuestra red neuronal mostró mejoras, reduciendo su tasa de error en el conjunto de entrenamiento del 20\% hasta un 11\%. Buscando mejorar aún más la tasa de error (pues aún era alta), se implementaron nuevas ideas.

\subsection{Mejora en BackPropagation: \textit{BackPropagation Adaptativo}}
Como en el BackPropagation con refuerzo parecía dar buenos resultados ir reduciendo progresivamente la tasa de aprendizaje ($\eta$) con forme avanzamos de época, surgió la idea de utilizar esta idea pero sobre todo el conjunto de entrenamiento. De esta forma, lo que se hacía era hacer un entrenamiento \textit{online} en el que en cada época, se reducía la tasa de error, de forma que los "saltos" hacía la solución óptima fuesen más pequeños conforme nos acercamos a ésta. En todas las épocas se usaba el conjunto completo de entrenamiento (esta es la diferencia real entre la mejora anterior y esta). La reducción de la tasa de aprendizaje se fijó finalmente como sigue:

\begin{equation}
	\eta_{e+1} = \eta_e (e * 0.1)
\end{equation}

Con la esperanza de que los resultados mejorasen, se probaron diferentes formas de ir actualizando la tasa de aprendizaje en cada época, y la que mejor pareció funcionar fue la fórmula anterior. Aún así, los resultados no mejoraron demasiado y la tasa de error se mantuvo en torno al 11-12\%.


\subsection{Generando Ruido}
Otra de las cosas que se ha probado ha sido introducir ruido en los datos, pues como vimos en clase, nos puede ayudar a que nuestra red aprenda características (patrones) más generales quitando de en medio la información que realmente no es útil, y que, al haber limpiado los datos ya no se distingue de los patrones que realmente podrían interesarnos. Por ejemplo, al limpiar las imágenes, los fondos y las esquinas son todas negras, lo que puede llevar a la red a aprender patrones relacionados con las esquinas, cuando no es lo que queremos pues no es la información importante. Al introducir ruido, las esquinas variarán y obviará esos patrones (ya que no existirán).
\\
Para introducir ruido, se elige al azar los pixels y el nivel de ruido. Si el pixel tiene un valor menor a 20, se cambia su valor con probabilidad del 2\%, a un nuevo valor de entre 0 y 120. Además, el entrenamiento se hace ahora con el doble de datos, pues tenemos la imagen original y una nueva imagen (que es una copia) a la que se le ha introducido ruido.
\\
Los resultados mejoraron, pero no demasiado, pues como se verá en los resultados, seguía en torno al 10-11\%.


\section{Resultados}
Después de realizar todas las modificaciones comentadas y de probar diferentes parámetros para ellas, se han obtenido varios resultados, algunos de los mejores son los siguientes.\footnote{Los experimentos con ruido se realizan con el doble de datos (imagen original + copia con ruido, para cada imagen).} \\

\begin{table}[!ht]
\centering
\caption{\textbf{Resutlados}}
\label{}
\begin{tabular}{ p{4cm}  | c | c | c | c | c | c }
\textbf{Algoritmo} & \textbf{Épocas} & \textbf{Capas Ocultas} & \textbf{Neuronas Ocultas} & \textbf{$\eta$} & \textbf{E.Entren.} & \textbf{E.Test} \\ \hline \hline
BackPropagtion Simple & 2 & 1 & 200 & 0.1 & 19.95\% & ?? \\ \hline
BackPropagtion Simple & 5 & 1 & 256 & 0.1 & 12.11\% & ?? \\ \hline
BackPropagtion Refuerzo & 7  & 1 & 256 & 0.1 & 11.98\% & ?? \\ \hline
BackPropagation Refuerzo & 13 & 1 & 300 & 0.1 & 12.04\% & ?? \\ \hline
BackPropagation Refuerzo & 3 & 1 & 256 & 0.1 & 12.18\% & ?? \\ \hline
BackPropagation Refuerzo & 10 & 1 & 400 & 0.1 & 11.99\% & ??\% \\ \hline
BackPropagation Refuerzo Con ruido & 3 & 1 & 200 & 0.1 & 11.94\% & 11.15\% \\ \hline
BackPropagation Refuerzo Con ruido & 2 & 1 & 400 & 0.1 & 10.62\% & 10.1\% \\ \hline
\end{tabular}
\end{table}

\end{document}